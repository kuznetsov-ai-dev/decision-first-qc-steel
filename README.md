## Decision-First ML для контроля качества  
### Triage при ограниченном ресурсе QC

Этот кейс — не про максимизацию accuracy.  
Он про **принятие правильных решений в условиях реальных ограничений**.

---

## TL;DR

В этом проекте я построил **decision-first ML-систему** для контроля качества в производстве стали, где **невозможно проверять все изделия**.

Вместо оптимизации стандартных метрик классификации задача была сформулирована как **risk-based triage**:
- модель ранжирует изделия по риску,
- служба контроля качества (QC) проверяет только **top-K%** из-за ограниченной пропускной способности.

В результате получена **устойчивая и интерпретируемая policy**, которая выявляет критичные дефекты **более чем в 3 раза лучше случайного отбора**, без избыточного усложнения модели.

---

## Контекст задачи

В промышленном контроле качества:

- проверка каждого изделия дорогостоящая или невозможна,
- разные дефекты имеют разную цену ошибки,
- **пропуск критичного дефекта обычно стоит значительно дороже**, чем лишняя проверка.

Поэтому ключевой вопрос здесь не:

> *«Какой класс дефекта у этого изделия?»*

а:

> **«Какие изделия нужно проверить в первую очередь при жёстком ограничении ресурса QC?»**

Это превращает задачу классификации в задачу **проектирования системы принятия решений**.

---

## Decision Framing (ключевая идея)

Система поддерживает операционные решения:

- **PASS** — пропустить без дополнительных действий  
- **QC_CHECK** — отправить на дополнительную проверку  
- **HOLD / REWORK** — удержать или отправить на переработку  
  (эти действия выходят за рамки данного кейса)

Ключевое ограничение:

- **ресурс QC ограничен** → можно проверить только **top-K%** изделий.

Следовательно, задача формулируется как **ранжирование по риску (triage)**, а не как “чистая” классификация.

---

## Обзор решения

1. Обучается **multiclass-модель** на 7 типах дефектов.
2. Явно задаётся **сценарий критичности дефектов**  
   (в данном кейсе — поверхностные царапины: `K_Scatch + Z_Scratch`).
3. Для каждого изделия считается **risk-score** на основе вероятностей модели:
    risk = P(K_Scatch) + P(Z_Scratch)
4. Изделия сортируются по risk-score.
5. На проверку отправляются **top-K%** изделий.

Важно:
- **K — это бизнес-ограничение**, а не настраиваемый параметр ML-модели.

---

## Метрики (что действительно важно)

Метрики были сознательно разделены на два уровня.

### ML-метрики (вспомогательные)

- Macro F1  
- Recall по классам  
- Confusion matrix  

### Decision-метрики (основные)

- **Recall@K** по критичным дефектам  
- **Lift относительно случайного отбора**  
- Чувствительность качества к величине K  

Именно эти метрики отражают поведение системы в реальном процессе.

---

## Ключевые результаты (decision-уровень)

Для сценария критичных царапин:

- система стабильно выявляет **в 3+ раза больше критичных дефектов**, чем случайный отбор;
- качество сохраняется при разных значениях K;
- увеличение сложности модели **не даёт значимого прироста Recall@K**.

Это подтверждает, что основная ценность здесь —  
**в постановке задачи и дизайне policy**, а не в погоне за метриками модели.

---

## Что было проверено и осознанно отброшено

Чтобы избежать избыточной сложности, я проверил типовые улучшения:

- бинарная модель (`critical vs non-critical`);
- cost-sensitive взвешивание классов;
- альтернативные схемы скоринга.

Ни одно из этих решений не дало значимого улучшения **decision-метрик**.

Я сознательно оставил **самое простое решение, которое работает не хуже**.  
Это осознанный выбор.

---

## Error Analysis (с точки зрения риска)

Были выявлены два ключевых режима ошибок:

1. **Опасные false negative**  
Часть критичных дефектов классифицируется как `Other_Faults` с низким risk-score.
2. **Пожиратели очереди (queue eaters)**  
Некоторые некритичные изделия получают высокий risk-score и занимают ресурс QC.

Эти эффекты напрямую влияют на требования к мониторингу и fallback-стратегиям.

---

## Production-мышление

При внедрении в реальную систему потребовалось бы:

- мониторить распределение risk-score;
- отслеживать долю критичных дефектов в top-K;
- контролировать дрейф ключевых признаков;
- иметь fallback-механизмы  
(временное увеличение K, ручной контроль).

В кейсе учитывается **операционная устойчивость**, а не только оффлайн-метрики.

---

## Структура репозитория

├── README.md    # Точка входа (этот файл)

├── docs/        # Полный разбор (Full Case)

├── src/         # Код обучения и оценки


Полный, подробный разбор кейса находится в директории **`docs/`**.

---

## Примечания

- Датасет: **Faulty Steel Plates** (публичный)
- Все доменные допущения зафиксированы явно
- Стоимость ошибок рассматривается как параметр чувствительности